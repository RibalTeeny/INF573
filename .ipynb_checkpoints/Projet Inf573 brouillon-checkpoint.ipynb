{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebc6592",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # grey images are stored in memory as 2D arrays, color images as 3D arrays\n",
    "import cv2 as cv2 # opencv computer vision library\n",
    "from skimage import io # for io.imread\n",
    "from matplotlib import pyplot as plt # ploting\n",
    "from matplotlib import colors # ploting\n",
    "\n",
    "# interactive notebook widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from skimage import transform\n",
    "from numpy import linalg\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b6d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(images, titles, nrows = 0, ncols=0, figsize = (15,20)):\n",
    "\n",
    "    if ncols == 0 and nrows == 0:\n",
    "      ncols = len(images)\n",
    "      nrows = 1\n",
    "    if ncols == 0:\n",
    "      ncols = len(images) // nrows\n",
    "    if nrows == 0:\n",
    "      nrows = len(images) // ncols\n",
    "      \n",
    "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, squeeze=False, figsize = figsize)\n",
    "    for i, image in enumerate(images):\n",
    "        axeslist.ravel()[i].imshow(image, cmap=plt.gray(), vmin=0, vmax=255)\n",
    "        axeslist.ravel()[i].set_title(titles[i])\n",
    "        axeslist.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout() # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4e4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlA  = 'A.jpg'\n",
    "urlB  = 'B.jpg'\n",
    "urlC  = 'C.jpg'\n",
    "urlD  = 'D.jpg'\n",
    "urlE  = 'E.jpg'\n",
    "urlF  = 'F.jpg'\n",
    "urlG  = 'G.jpg'\n",
    "urlH  = 'H.jpg'\n",
    "urlI  = 'I.jpg'\n",
    "urlK  = 'K.jpg'\n",
    "urlL  = 'L.jpg'\n",
    "urlM  = 'M.jpg'\n",
    "urlN  = 'N.jpg'\n",
    "urlO  = 'O.jpg'\n",
    "urlP  = 'P.jpg'\n",
    "urlQ  = 'Q.jpg'\n",
    "urlR  = 'R.jpg'\n",
    "urlS  = 'S.jpg'\n",
    "urlT  = 'T.jpg'\n",
    "urlU  = 'U.jpg'\n",
    "urlV  = 'V.jpg'\n",
    "urlW  = 'W.jpg'\n",
    "urlX  = 'X.jpg'\n",
    "urlY  = 'Y.jpg'\n",
    "#24 lettres on enleve le j et le Z car ce sont des mouvements\n",
    "\n",
    "imgA = io.imread(urlA)\n",
    "imgB = io.imread(urlB)\n",
    "imgC = io.imread(urlC)\n",
    "imgD = io.imread(urlD)\n",
    "imgE = io.imread(urlE)\n",
    "imgF = io.imread(urlF)\n",
    "imgG = io.imread(urlG)\n",
    "imgH = io.imread(urlH)\n",
    "imgI = io.imread(urlI)\n",
    "imgK = io.imread(urlK)\n",
    "imgL = io.imread(urlL)\n",
    "imgM = io.imread(urlM)\n",
    "imgN = io.imread(urlN)\n",
    "imgO = io.imread(urlO)\n",
    "imgP = io.imread(urlP)\n",
    "imgQ = io.imread(urlQ)\n",
    "imgR = io.imread(urlR)\n",
    "imgS = io.imread(urlS)\n",
    "imgT = io.imread(urlT)\n",
    "imgU = io.imread(urlU)\n",
    "imgV = io.imread(urlV)\n",
    "imgW = io.imread(urlW)\n",
    "imgX = io.imread(urlX)\n",
    "imgY = io.imread(urlY)\n",
    "\n",
    "urlTEST  = 'Test_L.jpg'\n",
    "imgTEST = io.imread(urlTEST)\n",
    "\n",
    "imgtest1 = io.imread('test1.jpg')\n",
    "imgtest2 = io.imread('test2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b3e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_points(img1, img2): #using AKAZE opencv feature extractor and descriptor to detect and compute features on 2 images\n",
    "    akaze = cv2.AKAZE_create()\n",
    "    \n",
    "    kp1, des1 = akaze.detectAndCompute(img1, None)\n",
    "    kp2, des2 = akaze.detectAndCompute(img2, None)\n",
    "    \n",
    "    return kp1, des1, kp2, des2\n",
    "\n",
    "def match_key_points(kp1, des1, kp2, des2):  #  match the features between images. The quality of each match is measured in the distance property of the match\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1,des2)\n",
    "    return sorted(matches, key = lambda x:x.distance) #sort the matches by increasing distance so that the first matches of the list are the more relevant. \n",
    "\n",
    "def showMatches(img1, kp1, img2, kp2, matches, name):\n",
    "    img = cv2.drawMatches(img1,kp1,img2,kp2,matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    imshow([img],[name])\n",
    "    \n",
    "def findHomography(matches, keypoint1, keypoint2): # find homography that transform img2 in img1 \n",
    "    src_pts = np.array([keypoint1[match.queryIdx].pt for match in matches])\n",
    "    dst_pts = np.array([keypoint2[match.trainIdx].pt for match in matches])\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts,cv2.RANSAC)\n",
    "    inliers = [ matches[m] for m in range(len(matches)) if mask[m]==1]\n",
    "    return H, inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4dc508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgtest1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img1 \u001b[38;5;241m=\u001b[39m\u001b[43mimgtest1\u001b[49m\n\u001b[0;32m      2\u001b[0m img2 \u001b[38;5;241m=\u001b[39mimgL\n\u001b[0;32m      3\u001b[0m kp1, des1, kp2, des2 \u001b[38;5;241m=\u001b[39m extract_key_points(img1, img2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imgtest1' is not defined"
     ]
    }
   ],
   "source": [
    "img1 =imgtest1\n",
    "img2 =imgL\n",
    "kp1, des1, kp2, des2 = extract_key_points(img1, img2)\n",
    "matches = match_key_points(kp1, des1, kp2, des2)\n",
    "showMatches(img1,kp1,img2,kp2,matches[:20],\"best 20 matches C et test\")\n",
    "H, inliers = findHomography(matches, kp1, kp2)\n",
    "showMatches(img1,kp1,img2,kp2,inliers,\"inliers only\")\n",
    "img = transform.warp(img1, inv(H), mode = 'edge')\n",
    "imshow([img],[\"Test homologie\"])\n",
    "print(\"H=\",H)\n",
    "print(\"de norme \", np.linalg.norm(H))\n",
    "\n",
    "img1 =imgL\n",
    "img2 =imgTEST\n",
    "kp1, des1, kp2, des2 = extract_key_points(img1, img2)\n",
    "matches = match_key_points(kp1, des1, kp2, des2)\n",
    "showMatches(img1,kp1,img2,kp2,matches[:20],\"best 20 matches L et test\")\n",
    "H, inliers = findHomography(matches, kp1, kp2)\n",
    "showMatches(img1,kp1,img2,kp2,inliers,\"inliers only\")\n",
    "img = transform.warp(img1, inv(H), mode = 'edge')\n",
    "imshow([img],[\"Test homologie\"])\n",
    "print(\"H=\",H)\n",
    "print(\"de norme \", np.linalg.norm(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3dc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
